{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ba83ea-823c-492a-b94e-7b1cbb4c95d3",
   "metadata": {},
   "source": [
    "### Download Local Model with Ollama\n",
    "\n",
    "(1) Download Ollama:\n",
    "https://ollama.com/download\n",
    "\n",
    "(2) Select a model, for example Mistral 7B or Llama 3.1:\n",
    "https://ollama.com/library/mistral:7b\n",
    "https://ollama.com/library/llama3.1\n",
    "\n",
    "(3) Download the model using command line:\n",
    "ollama run mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37679fd1-1884-46cb-8301-7bec0c4a7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "    \n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor, create_react_agent\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "#from langchain.agents import Tool\n",
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c078fc-e433-4240-b256-1279e9d4cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001533ed-b1ee-4196-8152-65a10768514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_stock_prices_and_volumes(symbol: str, start_date: str, end_date: str) -> str:\n",
    "    \"\"\"Get stock data.\"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        data = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        if data.empty:\n",
    "            return f\"No data found for {symbol} between {start_date} and {end_date}.\"\n",
    "        \n",
    "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']]  \n",
    "        summary = data.to_string()\n",
    "        \n",
    "        return f\"Stock prices and volumes for {symbol} from {start_date} to {end_date}:\\n\\n{summary}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching stock prices and volumes for {symbol}: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def calculate_var(symbol: str, start_date: str, end_date) -> str:\n",
    "    \"\"\"\n",
    "    Calculates the 95% Value at Risk (VaR) using historical data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch historical prices\n",
    "        var_data = get_stock_prices_and_volumes(symbol, start_date, end_date)\n",
    "\n",
    "        if var_data.empty:\n",
    "            return f\"No data found for {symbol} between {start_date} and {end_date} for VaR calculation.\"\n",
    "\n",
    "        # Calculate daily returns from closing prices\n",
    "        var_data['Returns'] = var_data['Close'].pct_change().dropna()\n",
    "\n",
    "        # Compute the 95% VaR\n",
    "        var = np.percentile(var_data['Returns'].dropna(), 5)\n",
    "\n",
    "        return (\n",
    "            f\"The Value at Risk (VaR) for {symbol} \"\n",
    "            f\"using data from {start_date} to {end_date} is approximately {var:.4%}.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating VaR for {symbol}: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3627e9e4-3c75-42da-be6c-1880fcfd1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, get_stock_prices_and_volumes, calculate_var]\n",
    "llm = ChatOllama(\n",
    "    #model=\"llama3.1\",\n",
    "    model='mistral:7b',\n",
    "    temperature=0,\n",
    ").bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c5a583-acc7-4c14-ab22-482efa3f1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to convert date to YYYY-MM-DD format.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the Tools agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0eac26-0ff6-486e-8f81-3671827e854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"when is the initial release date of bitcoin\", })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78815ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b8cff-6e20-4718-977e-ffd4c288d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"what is the average prices for AAPL stock between 2023-01-01 and 2023-02-01? Use provided tools.\", })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654b083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import openai\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.schema.agent import AgentFinish\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "import panel as pn\n",
    "import param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9fa6f-9999-4ae6-bde2-c6d6fde9bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cbfs(param.Parameterized):\n",
    "    \n",
    "    def __init__(self, tools, **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "\n",
    "        #openAI\n",
    "        \n",
    "        # self.functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "        # self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)        \n",
    "        # self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
    "        # self.prompt = ChatPromptTemplate.from_messages([\n",
    "        #     (\"system\", \"You are helpful assistant\"),\n",
    "        #     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        #     (\"user\", \"{input}\"),\n",
    "        #     MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        # ])\n",
    "        # self.chain = RunnablePassthrough.assign(\n",
    "        #     agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "        # ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n",
    "        # self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
    "\n",
    "        #Ollama\n",
    "        \n",
    "        self.tools = tools\n",
    "        self.model = ChatOllama(\n",
    "            model=\"\",\n",
    "            temperature=0,\n",
    "        ).bind_tools(self.tools)\n",
    "          \n",
    "        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"You are a helpful assistant.  \\\n",
    "                    Make sure to convert the user input date to YYYY-MM-DD format. \\\n",
    "                    Conver the use input token name to token ticker symbol, in lower case. \\\n",
    "                    For example, convert Bitcoin to btc and Ethereum to eth. \",\n",
    "                ),\n",
    "                (\"placeholder\", \"{chat_history}\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.agent = create_tool_calling_agent(self.model, self.tools, self.prompt)   \n",
    "        self.qa = AgentExecutor(agent=self.agent, tools=self.tools, verbose=False, memory=self.memory)\n",
    "\n",
    "    \n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return\n",
    "        inp.value = ''\n",
    "        result = self.qa.invoke({\"input\": query})\n",
    "        self.answer = result['output'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
    "            pn.Row('Answer:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return \n",
    "\n",
    "tools = [wiki, get_stock_prices_and_volumes, calculate_var]\n",
    "\n",
    "cb = cbfs(tools)\n",
    "\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
    "\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=400),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# Financial_QnA_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1))\n",
    ")\n",
    "dashboard\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
    "\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=400),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# Financial_QnA_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1))\n",
    ")\n",
    "dashboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13371cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
